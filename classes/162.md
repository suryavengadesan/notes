# Lecture 3 

- Thread 
	- Execution Context 
		- Fully describes program state 
		- Programm counter, registers, execution flags, stack 
- Address Space (w/o translation)
	- Set of memory addresses accessible to program 
	- May be distinct from memory space of the physical machine 
- Process 
	- Instance of running a program
	- Protected address space + 1 or more threads 
- Dual Mode Operation + Protection 
	- Only systm has ability to access certain resources 
	- Combined with translation, isolates programs with each other and the OS from programs 

- Illusion of Multiple Processors 
	- Programmer's View
		- Multiple CPUs to Shared Memory 

- Threads are virtual cores 
- Multiple threads => multiplex hardware in time 
- Thread is executing on a processor when reisdent in processor's registers

- Each virtual core has: 
	- Program counter, stack pointer 
	- Registers

- Where is it? 
	- On real physical core 
	- Save in memory 
		- Thread control block 

- Virtual Address Space 

- Address Space 
	- Set of accessible addresses + associated state 
		- 32 bits => 2^32 = 4 billion addresses
		- 64 bits => 2^64 = 18 quintillion 

- Virtual Address Space 
	- Processor's view of memory 
		- AD is independent of physical storage 
	- Translation through page table
		- Page table is stored in operation table  

- Process 
	- protected environment with one or more thread 

- PintOS only has 1 thread 

- Process runs programs 
	- protected from each other 
	- OS protected from them 

- Modern OS
	- Anything outside the kernel is a process 

- Motivation for threads 
	- Device drivers get added in kernel mode 
	- Need to MTAO (do multiple things at once)
		- Networked servers 
		- Parallel programs 
		- Programs with user interface 
		- Network with disk bound programs 

- Threads are unit of concurrency 
	- Each thread represents one task

- Multiprocessing vs. Multiprogramming 
	- Multiprocessing
		- multiple CPUS
	- Multiprogramming 
		- multiple jobs and processes 
	- Multithreading 
		- multiple threads and processes 

- Concurrent Threads 
	- Schedule runs threads in any order and interleaving 
	- Thread may run to completion 
		- Time-slice in big chunks or small chunks

- Need to design for correctness

- Concurrency is not Parallelism 
	- Parallelism => Doing multiple things at once (MTAO)
	- Concurrency => Doing mulitple things simultaneously

- Two threads on single core system
	- Run two threads on the same core 

- Create thread 
	- Spawn new thread running given procedure 

- Jeff Dean's "Numbers Everyone Should Know" 
	- L1 Cache Reference
	- Branch Mispredict 
	- ....
	- Disk seek 
		- Handle I/O in separate thread to avoid blocking progress

- Threads Mask I/O Latency 
	- 3 States 
		- Running
		- Ready 
		- Blocked 

- System Call Interface 
	- Splits User (User Mode) from System (Kernel Mode)
	- OS Libraries perform system calls 


# Lecutre 10 - Scheduling 1: Concepts and Classic Policies

- Monitor and Condition Variables
	- Monitor - lock with 0>= condition variables
		- programming paradigm (e.g. Java)
	- Condition Variable - queue of threads waiting inside critical section
	- Operations
		- Wait
		- Signal
		- Broadcast
	
- Layers of I/O

- Different Types of I/O
	- Process Management
	- Memory Management
	- Filesystems
	- Device Control
	- Networking

- Internal OS File Descriptor
	- Internal Data Structure of file 
		- Where it resides
		- Its status
		- How to access it

- Device Driver
	- Device-specific code in kernel 
	- Two Pieces
		- Top Half
		- Bottomg Half 

- Life Cycle of I/O Request
	- User Progam
	- Kernel  I/O Subsystem
	- Device Driver Top Half
	- Device Driver Bottom Half
	- Device Hardware

- Scheduling
	- Which thread runs on CPU next 
	- Many goals, policies, and schedulers

- CPU Bursts 
	- Programs burst between CPU and I/O 

- Scheduling Policy Goals/Criteria
	- Minimize response time
	- Maximize throughput
	- Fairness

- Gantt Chart

- First-come, First-served (FCFC) Scheduling
	- i.e. FIFO, Run until done
	- Convoy Effect -> short process stuck behind long process

- Round Robin (RR) Scheduling
	- Each process gets one time quantum
	- Scheduled back to end of queue

- SAD ASF 

# Lecture 23 

## Networking Layering 

- Layering
	- Complex services out of simplers ones 
	- Physical link layer is limited 
		- Maximum Transfer Unit = packet size of 100-1500 bytes 
		- Routing limited to physical link wire with switch 
	
## UDP Transport Protocol 
- IP Protocol 17 
	- IP Header 
		- Adds minimal header to deliver from process to process
	- IP Source Port 
	- UDP Data 

- Lower Overhead 
	- Used for high bandwitch message (images, videos)

# Lecture 24 

- Distributed Consensus Making 
	
- Consensus Problem
	- All nodes propose a value 
	- Seom nodes might crash and stop responding 
	- All remaining nodes decide on some value 
- Distriubted Decision Making 
	- Choose between true and false 
	- Choose between commit and abort 
- Two Phase Commit Protocol 
	- Persistent Stable log on each machine 
	- Prepare Phase
	- Commit Phase 

- Network Protcols 
	- Many Levels 
		- Physical Level -> mechanical and electrical network 
			- Ethernet, Wifi, LTE
		- Link Level -> packets formats/error control
		 	- Ethernet, Wifi, LTE
		- Network Level -> network routing, addressing
			- IP 
		- Transport Level -> reliable message delivery
			- UDP TCP 
		- Application Level 
			- RPC, NFS, WWW, E-mail, SSH 

- Layering 
	- build complex services from simpler ones 
	- each layer provides services needed by many higher layers by utilizing services provided by lower layers 

- Physical link layer is limited 
	- Packets are of limited size
		- Maximum Transfer Unit (MTU)
			- Packets of limited size 
	- Routing in limited with physical link 
	- Construct secure, ordered, message service routed to anywhere 

- Physical Reality (Packets)
	- MTU -> Limited size 
	- Unordered (sometimes)
	- Unreliable
	- Machine-to-Machine 
	- Only on local area net 
	- Asynchronous 
	- Insecure 
- Abstractions (Messages)
	- Arbitrary Size 
	- Ordered 
	- Reliable 
	- Process-to-process
	- Routed anywhere 
	- Synchronous 
	- Secure 

- IPV4 Packet Format 
	- Wrapper of data 
	- Can use IP format to send data 
		- from one machine to same machine 
		- frome one machine to another machine 

- Internet Architecture 
	- Five Layers 
		- Lower three layers implemented everywhere
		- Top two layers implemented only at hosts 
	- Host A, Router, Host B 

- Layering Analogy
	- Packets in envelopes

- Internet Transport Protocols 
	- Datagram service (UDP) - IP Protocol 17 
		- No-frills extension of best-effort IP 
		- Multiplexing and demultiplexing among processes 
	- Reliable, in-order deliver (TCP) - IP Protocol 6
		- Connection set-up & tear-down 
		- Discarding corrupted packets (segments)
		- Retransmission of lost packets (segments)
		- Flow control 
		- Congestion control 
	- Other Examples 
		- DCCP (33) - datagram congestion control protocol 
		- RDP (26) - reliable data protocol 
		- SCTP (132) - stream control transmission protocol

- Sockets in concept 
	- Client
		- Create client socket 
		- Connect it to server (host:port)
		- Connectoin Socket -> Connection Socket
		- Close client socket 
	- Server
		- Create Server Socket 
		- Bind it to an address 
		- Listen for connection 
		- Accept syscall()
		- Close connection socket 
		- Close server socket

- Reliable Message Delivery - The Problem 
	- All physical networks can garble or drop packets
	- Physical media -> packet not transmitted received
		- If transmit close to maximum rate
		- If transmit at lowest voltage such that error connection just starts correct errors
	- Congestion -> no place to put incoming packets
		- Point-to-point network -> insufficient queue at switch/router
		- Broadcast link -> two host try to use same link 
		- In any network -> insufficient buffer space at destination 
		- Rate mismatch -> what is sender send faster than receiver can process 

- TCP (Transmission Control Protocol) - IP Protocol 6
	- Stream in -> Router -> Stream out
	- Reliable byte stream between two processes on different machine
		- Over internet (read, write, flush)

- TCP Details 
	- Fragments byte stream into packets 
		- Hand packets to IP 
		- IP may also fragment by itself 
	- Uses window-based acknowledgement protocol 
		- Window reflects storage at receiver
		- Window shoudl reflect speed capacity of network 

- Dropped Packets
	- Physical hardware problems (bad wire, bad signal)

- Ensure transmission of packets
	- Send packet, send back ACK message
		- Detects garbling via check sum 
	- Timeout and retransmission

- Stop-and-wait (No packet loss)
	- Send, wait for ACK, repeat 
	- RRT (Round Trip Time)
		- Time takes packet to travel from sender to receiver and back 
	- For symmetric latency 
		- RTT = 2d

- Stop-and-wait (No Packet Loss)
	- Little's Law applied to the network
	- Loss recovery relies on timeouts 

- Stop-and-wait (With Packet Loss)
	- Loss recovery relies on timeouts 

- Deal with Message Duplication

- Advantage of Moving Away from Stop-and-wait 
	- Layer space of acknowledgements
		- Pipelineling: Don't wakt for ACK before sending 
	- ACKs serve dual prupose 
		- Reliability -> confirm packet recieved
		- Ordering -> Packets can be reorderd at destination 
	- Compute data in flight

- Remote Procedure Call (RPC)
	- Raw messaging is a bit too low-level for programming 

- RPC Concept 
	- Client(Caller) -> call -> Client Stub -> send 
	- Server(Callee) <- return <- Server Stub <-receive

- Client Stub -> Packet Handler -> Network -> Packet Handler -> Server Stub 

- RPC Implementation 
	- Stub provides glue on client and server
		- Client stub responsiblef or marshalling arguments and unmarshalling return values

- RPC Details 
	- Equivalence with regular procedure call 
		- Parameters -> request message
		- Resut -> reply message
		- Name of procedure -> passed in request message
		- Return address -> mbox2
	- Cross-platform issues 
	- Binding -> process of converting a user-visible name into network endpoint 
		- Static -> fixed at compile time 
		- Dynamic -> performed at run time 
	- Dynamic Binding 
		- RPC systems determines binding from name service 
		- Benefits
			- Access Control -> check who permitted access service
			- Fail-over -> if server fails, use different one
	- Multiple Servers 
		- Give flexibility of binding time 
	- Non-atomic Failures 
		- different failure modes on single machine 
			- user level bug 
			- macihine failure 
		- Inconsistent view of word
			- Did cache get written back?
			- Did server perform request or not?
		- Solution 
			- Distributed transaction 
			- Byzantine Commit 
	- RPC Systems
		- CORBA
		- DCOM
		- RMI 
- Microkernel operating systems 
	- Monolithic vs. microkernel 
	- Benefits
		- Fault isolation -> Bugs are isolated
		- Enforces modularity 
- Network-attached storage
	- CAP Theorem by Eric Brewer
		- Consistency -> changes appear to everyone in same serial order
		- Availability -> get results at any time 
		- Partition-Tolerance -> system continue to work when network become partitioned
	- Cannot have all three at same time 

- Summary 
	- TCP 
	- RPC 
	- Distributed File System
	- Cache Consistency 

# Lecture 25: Distributed Storage, NFS and AFS, Key Value Stores

- Recall 
	- RPC Information Flow
	- CAP Theorem 

- Distributed File Systems 
	- Model
		- Client -> Read File -> Server 
		- Client <- Data Sent <- Server 
	- Mount remote files into local file system 
	- Naming Choices
		- Tuple Name => (Hostname, localname)
		- Global name space => unique global filename (with hashing)

- VFS -> Virtual File System 
	- allow for multiple filesystem types on different networks

- Layers of I/O
	- Device Driver

- Virtual Filesystem Switch
	- VFS -> virtual abstraction similar to local file system 
	- Provide virtual superblocks, inodes, files
	- Compatible with local and remote filesystems

- VFS Common File Model in Linux 
	- Primary Object Types 
		- superblock object
		- inode object 
		- dentry object 
		- file object

- Simple Distributed File System
	- Read RPC, Return Data
	- Remote disk => reads and writes forwarded to server
	- Use RPC to translate system into remote requests
	- Advantage
		- Server provides consistent view of file system to multiple clients
	- Challenges
		- Slow performance
	
- Caching
	- Add caches to reduce network load
		- read(f1)
		- write(f1)
	- Advantage
		- Operations can be done locally
	- Challenges
		- Cache data not commited during failures
		- Caches not consistent

- Dealing with Failures
	- Server crashes

- Stateless Protocol 
	- Request contains information requred to service
		- e.g. HTTP, NFS
- Idempotent Operations 
	- Multiple executions equals to one operation

- Case Study: NFS (Network File System)
	- Three Layers
		- UNIX file-system interface
			- open, read, write, close calls + file descriptors 
		- VFS layer
			- distinguishes local from remote files
		- NFS service layer
			- bottom layer of architecture
	- NFS Protocol 
		- RPC for file operation on server
	- Write-through caching


# Resouces  
- Spring 2020 Lectures
	- https://www.youtube.com/@johnkubiatowicz3737/videos 

# Textbook 

# Volume 1
Operating Systems - Principles and Practice

Volume 1 - Kernels and Processes

OS => (1) referee (2) illusionist (3) glue 

Kernel Abstraction => 

process => execution of application with restricted rights 
	=> protection is provided by os kernel 

process abstraction
	=> program executuble => compiler's output machine code and data 
	=> execution stack => holds local variables during procedure calls 
	=> heap => memory to dynamically allocate data structures for program 

OS execution 
	=> set stack pointer
	=> jump into first instruction 

Analogy
	process => program
	object => class 

Process Control Block 
	=> data structure that keeps track of various processes 
	=> contains information about process 
		-> where it is stored in memory
		-> where executuble image is stored in disk 
		-> which user asked to execute 
		-> privileges of process 
		-> etc 

program consistes of concurrent activites => threads 
	- each thread has separate program counter and stack 
	- process = multiple threads 

dual operation mode 
	- 

Programming Interface 

# Volume 2 - Concurrency

## Chapter 7 - Scheduling 

- Task -> user request 
- Response Time -> user perceived time to complete task 
- Starvation -> lack of progress for task

## 7.1 - Uniprocessor Sheduling 
- Simple Policies
	- FIFO
	- SJF 
	- RR 

- Resource Allocatin System
	- Processors
	- Memory
	- Network
	- Disk 

- Workload => Set of tasks

- Preempt (stop task)
	- Timer Interrupt
	- Higher priority task 

## FIFO

## SJF

- Shortest job first - always schedule task with shortest remaining time 
	- Assumes each task time is known
		- Approximated alogirthms exist
	- Minimizes average task time 

# Volume 3 - Memory Management 

# Volume 4 - Persistent Storage 

References
https://www.kea.nu/files/textbooks/ospp/osppv1.pdf

# Tools

- Python Multiprocessing Tool 
	- process based parallelism 
	- https://docs.python.org/3/library/multiprocessing.html 

- Python Threading Tool
	- thread based parallelism
	- https://docs.python.org/3/library/threading.html#module-threading


# Industry Tools


# Docker

## Docker run 

- IPC -> interprotocol 
https://docs.docker.com/engine/reference/run/#ipc-settings---ipc